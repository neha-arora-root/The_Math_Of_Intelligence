{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Data picked: https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n",
    "'''\n",
    "df = pd.read_csv(\"/Users/neha.arora/Downloads/train.csv\", header=None)\n",
    "dfTrain = df.filter([3,80], axis=1).loc[1:].dropna()\n",
    "dfTrain = dfTrain.values.astype(float)\n",
    "\n",
    "df2 = pd.read_csv(\"/Users/neha.arora/Downloads/train.csv\", header=None)\n",
    "dfTest = df2.filter([3], axis=1).loc[1:].dropna()\n",
    "dfTest = dfTest.values.astype(float)\n",
    "\n",
    "weights = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The independent variable takes into account the feature:\n",
    "GrLivArea: Above grade (ground) living area square feet\n",
    "\n",
    "Variable being predicted: SalePrice\n",
    "\n",
    "Plots to analyze the relationship of each variable with the variable being predicted\n",
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "plt.scatter(dfTrain[:,0], dfTrain[:,1])\n",
    "plt.title(\"Living Area vs Cost of House\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Feature scaling (normalization) to ensure proportionate contribution of features to objective function\n",
    "X(i) = (X(i) - mean(X(i)))/std(X(i)) , X(i) represents the i th feature of dataset\n",
    "'''\n",
    "\n",
    "def normalizeFeatures(X):\n",
    "    mean = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    normalizedX = (X-mean)/std\n",
    "    return normalizedX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Predict the value(s) for given data point(s) X and weight vector theta\n",
    "h(theta, X) = X * theta'\n",
    "where h(theta, X) is the value based on hypothesis given theta and X\n",
    "\n",
    "X : [m x (n+1)]\n",
    "theta : [1 x (n+1)]\n",
    "(m: examples in data set\n",
    " n: feature space of X)\n",
    " \n",
    "Returns predicted values y\n",
    "y : [m x 1]\n",
    "'''\n",
    "def predict(X, theta):\n",
    "    y = np.dot(X, theta.T)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Objective function that needs to be minimized for optimal solution\n",
    "Error calculation using SSE: Sum of Squared Errors\n",
    "E = 1/(2*m) * ((h(theta,X) - y) ** 2)\n",
    "\n",
    "Returns the sum of squared errors value for the data point(s) X\n",
    "'''\n",
    "\n",
    "def SSE(X, theta, y):\n",
    "    predicted = predict(X, theta)\n",
    "    error = predicted - y\n",
    "    squaredErrors = np.dot(error.T, error)\n",
    "    sse = np.sum(squaredErrors)/(2*X.shape[0])\n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Gradient calculation for the objective function\n",
    "(E : SSE, \n",
    "theta : w (the weight vector))\n",
    "\n",
    "dE/dw = dE/dh * dh/dw\n",
    "(h : predict function for given X and theta (w))\n",
    "\n",
    "dE/dw(i) = 1/(2*m) * (-2 * (h(theta, X) - y)) * dh/dw(i)\n",
    "dE/dw(i) = -1/m * (h(theta, X) - y)) * X(i)\n",
    "\n",
    "Returns a vector of gradients\n",
    "\n",
    "'''\n",
    "def gradient(X, theta, y):\n",
    "    grad = np.dot(X.T, predict(X, theta) - y)/X.shape[0]\n",
    "    return grad.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Gradient Descent to minimize loss\n",
    "\n",
    "Two approaches:\n",
    "1) Batch Gradient Descent: Use all the examples of the training set to determine the update in weight parameters\n",
    "2) Stochastic Gradient Descent: Use one example of the training set at a time to update weight parameters\n",
    "'''\n",
    "def gradient_descent_step(X, theta, y, alpha):\n",
    "    grad = gradient(X, theta, y)\n",
    "    theta = theta - alpha * grad\n",
    "    return theta\n",
    "\n",
    "def batch_gradient_descent (X, theta, y, num_iters, alpha):\n",
    "    error_record = np.zeros(num_iters)\n",
    "    for iter in range(num_iters):\n",
    "        error_record[iter] = SSE(X, theta, y)\n",
    "        theta = gradient_descent_step(X, theta, y, alpha)\n",
    "    return [theta, error_record]\n",
    "\n",
    "def stochastic_gradient_descent (X, theta, y, num_iters, alpha):\n",
    "    error_record = np.zeros(num_iters * X.shape[0])\n",
    "    counter = 0\n",
    "    for rec in range(X.shape[0]):\n",
    "        for iter in range(num_iters):\n",
    "            error_record[counter] = SSE(X, theta, y)\n",
    "            counter = counter+1\n",
    "            theta = gradient_descent_step(X, theta, y, alpha)\n",
    "    return [theta, error_record]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Verify gradients computed with normal equation\n",
    "\n",
    "y = X * Theta\n",
    "X' * y = X' * X * Theta\n",
    "X' * y = (X' * X) * Theta\n",
    "Theta = ((X' * X) ** -1) * X' * y\n",
    "\n",
    "'''\n",
    "def verifyTheta(X, y):\n",
    "    thetaComputed = np.dot(np.linalg.pinv(np.dot(X.T, X)), np.dot(X.T, y))\n",
    "    return thetaComputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -5.19323222e-18   3.51799097e-01]\n",
      "[  8.36697347e-06   3.51809137e-01]\n",
      "[  1.80362523e-16   3.51799097e-01]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Initialize weights and compare results of gradient descent and normal equation\n",
    "'''\n",
    "\n",
    "for i in range(weights.shape[0]):\n",
    "    weights[i] = random.random()\n",
    "\n",
    "XTrain = normalizeFeatures(dfTrain)\n",
    "XTest = normalizeFeatures(dfTest)\n",
    "\n",
    "XTemp = np.ones((XTrain.shape[0], XTrain.shape[1]+1))\n",
    "XTemp[:,1:] = XTrain\n",
    "XTrain = XTemp\n",
    "\n",
    "XTemp2 = np.ones((XTest.shape[0], XTest.shape[1]+1))\n",
    "XTemp2[:,1:] = XTest\n",
    "XTest = XTemp2\n",
    "\n",
    "features = XTrain[:,0:2]\n",
    "pred = XTrain[:,2]\n",
    "thetaComputed = verifyTheta(features, pred)\n",
    "print (thetaComputed)\n",
    "[theta1, error_record1] = batch_gradient_descent(features, weights, pred, 1000, 0.01)\n",
    "print (theta1)\n",
    "[theta2, error_record2] = stochastic_gradient_descent(features, weights, pred, 1000, 0.01)\n",
    "print (theta2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
